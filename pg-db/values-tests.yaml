
finalizers:
# Set this if you want that operator deletes the PVCs on cluster deletion
#  - percona.com/delete-pvc
# Set this if you want that operator deletes the ssl objects on cluster deletion
#  - percona.com/delete-ssl

crVersion: 2.5.0
repository: percona/percona-postgresql-operator
image: percona/percona-postgresql-operator:2.5.0-ppg16.4-postgres
imagePullPolicy: Always
postgresVersion: 16
# port: 5432
pause: false
unmanaged: false
standby:
  enabled: false
  # host: "<primary-ip>"
  # port: "<primary-port>"
  # repoName: repo1

# customRootCATLSSecret:
#   name: cluster1-ca-cert
#   items:
#     - key: "tls.crt"
#       path: "root.crt"
#     - key: "tls.key"
#       path: "root.key"
customTLSSecret:
  name: ""
customReplicationTLSSecret:
  name: ""

# openshift: true

users:
  - name: odilon
    databases:
      - testing_interview
    options: "SUPERUSER"
    password:
      type: ASCII
    secretName: "odilon-credentials"

# databaseInitSQL:
#   key: init.sql
#   name: cluster1-init-sql

# dataSource:
#   postgresCluster:
#     clusterName: cluster1
#     repoName: repo1
#     options:
#     - --type=time
#     - --target="2021-06-09 14:15:11-04"
#     tolerations:
#     - effect: NoSchedule
#       key: role
#       operator: Equal
#       value: connection-poolers
#   pgbackrest:
#     stanza: db
#     configuration:
#     - secret:
#         name: pgo-s3-creds
#     global:
#       repo1-path: /pgbackrest/postgres-operator/hippo/repo1
#     options:
#     - --type=time
#     - --target="2021-06-09 14:15:11-04"
#     tolerations:
#     - effect: NoSchedule
#       key: role
#       operator: Equal
#       value: connection-poolers
    # repo:
    #   name: repo1
    #   s3:
    #     bucket: "my-bucket"
    #     endpoint: "s3.ca-central-1.amazonaws.com"
    #     region: "ca-central-1"
    #   gcs:
    #     bucket: "my-bucket"
    #   azure:
    #     container: "my-container"

    volumes:
      pgDataVolume:
        pvcName: db-pgdata
        directory: pgdata

      pgWALVolume:
        pvcName: db-pgwal
        directory: pgwal

      pgBackRestVolume:
        pvcName: db-pgbr-repo
        directory: pgbackrest

# expose:
#   annotations:
#     my-annotation: value1
#   labels:
#     my-label: value2
#   type: LoadBalancer
#   loadBalancerSourceRanges:
#     - 10.0.0.0/8
# exposeReplicas:
#   annotations:
#     my-annotation: value1
#   labels:
#     my-label: value2
#   type: LoadBalancer
#   loadBalancerSourceRanges:
#     - 10.0.0.0/8

instances:
- name: database
  replicas: 3

  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        podAffinityTerm:
          labelSelector:
            matchLabels:
              postgres-operator.crunchydata.com/data: postgres
          topologyKey: kubernetes.io/hostname
  resources:
    requests:
      cpu: 2
      memory: 2Gi
    limits:
      cpu: 2
      memory: 2Gi
# containers:
#    replicaCertCopy:
#      resources:
#        limits:
#         cpu: 200m
#         memory: 128Mi
#  sidecars:
#  - name: testcontainer
#    image: mycontainer1:latest
#  - name: testcontainer2
#    image: mycontainer1:latest
#
#  topologySpreadConstraints:
#    - maxSkew: 1
#      topologyKey: my-node-label
#      whenUnsatisfiable: DoNotSchedule
#      labelSelector:
#        matchLabels:
#          postgres-operator.crunchydata.com/instance-set: instance1
#
#  tolerations:
#  - effect: NoSchedule
#    key: role
#    operator: Equal
#    value: connection-poolers
#
#  priorityClassName: high-priority
#
#  securityContext:
#    fsGroup: 1001
#    runAsUser: 1001
#    runAsNonRoot: true
#    fsGroupChangePolicy: "OnRootMismatch"
#    runAsGroup: 1001
#    seLinuxOptions:
#      type: spc_t
#      level: s0:c123,c456
#    seccompProfile:
#      type: Localhost
#      localhostProfile: localhost/profile.json
#    supplementalGroups:
#    - 1001
#    sysctls:
#    - name: net.ipv4.tcp_keepalive_time
#      value: "600"
#    - name: net.ipv4.tcp_keepalive_intvl
#      value: "60"

  walVolumeClaimSpec:
    storageClassName: standard
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 2Gi
  dataVolumeClaimSpec:
    storageClassName: standard
    accessModes:
    - ReadWriteOnce
    resources:
      requests:
        storage: 10Gi

#  tablespaceVolumes:
#    - name: user
#      dataVolumeClaimSpec:
#        accessModes:
#          - 'ReadWriteOnce'
#        resources:
#          requests:
#            storage: 1Gi

proxy:
  pgBouncer:
    replicas: 0
    image: percona/percona-postgresql-operator:2.5.0-ppg16.4-pgbouncer1.23.1
#    exposeSuperusers: true
#    resources:
#      limits:
#        cpu: 200m
#        memory: 128Mi
#    containers:
#      pgbouncerConfig:
#        resources:
#          limits:
#           cpu: 200m
#           memory: 128Mi

#      expose:
#        annotations:
#          my-annotation: value1
#        labels:
#          my-label: value2
#        type: LoadBalancer
#        loadBalancerSourceRanges:
#          - 10.0.0.0/8

  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        podAffinityTerm:
          labelSelector:
            matchLabels:
              postgres-operator.crunchydata.com/role: pgbouncer
          topologyKey: kubernetes.io/hostname

#      tolerations:
#      - effect: NoSchedule
#        key: role
#        operator: Equal
#        value: connection-poolers
#
#     securityContext:
#       fsGroup: 1001
#       runAsUser: 1001
#       runAsNonRoot: true
#       fsGroupChangePolicy: "OnRootMismatch"
#       runAsGroup: 1001
#       seLinuxOptions:
#         type: spc_t
#         level: s0:c123,c456
#       seccompProfile:
#         type: Localhost
#         localhostProfile: localhost/profile.json
#       supplementalGroups:
#       - 1001
#       sysctls:
#       - name: net.ipv4.tcp_keepalive_time
#         value: "600"
#       - name: net.ipv4.tcp_keepalive_intvl
#         value: "60"
#
#      topologySpreadConstraints:
#        - maxSkew: 1
#          topologyKey: my-node-label
#          whenUnsatisfiable: ScheduleAnyway
#          labelSelector:
#            matchLabels:
#              postgres-operator.crunchydata.com/role: pgbouncer
#
#      sidecars:
#      - name: bouncertestcontainer1
#        image: mycontainer1:latest
#
#      customTLSSecret:
#        name: keycloakdb-pgbouncer.tls
#
#      config:
#        global:
#          pool_mode: transaction

backups:
  trackLatestRestorableTime: true
  pgbackrest:
# #    metadata:
# #    labels:
    image: percona/percona-postgresql-operator:2.5.0-ppg16.4-pgbackrest2.53-1
#     containers:
#       pgbackrest:
#         resources:
#           limits:
#             cpu: 200m
#             memory: 128Mi
#       pgbackrestConfig:
#         resources:
#           limits:
#             cpu: 200m
#             memory: 128Mi
#
#    configuration:
#      - secret:
#          name: cluster1-pgbackrest-secrets
#    jobs:
#      priorityClassName: high-priority
#      resources:
#        limits:
#          cpu: 200m
#          memory: 128Mi
#      tolerations:
#      - effect: NoSchedule
#        key: role
#        operator: Equal
#        value: connection-poolers
#
#      securityContext:
#        fsGroup: 1001
#        runAsUser: 1001
#        runAsNonRoot: true
#        fsGroupChangePolicy: "OnRootMismatch"
#        runAsGroup: 1001
#        seLinuxOptions:
#          type: spc_t
#          level: s0:c123,c456
#        seccompProfile:
#          type: Localhost
#          localhostProfile: localhost/profile.json
#        supplementalGroups:
#        - 1001
#        sysctls:
#        - name: net.ipv4.tcp_keepalive_time
#          value: "600"
#        - name: net.ipv4.tcp_keepalive_intvl
#          value: "60"
#
    # global:
      # repo1-retention-full: "14"
      # repo1-retention-full-type: time
      # repo1-path: /pgbackrest/postgres-operator/cluster1/repo1
      # repo1-cipher-type: aes-256-cbc
      # repo1-s3-uri-style: pgbackrest-config
      # repo2-path: /pgbackrest/postgres-operator/cluster1-multi-repo/repo2
    repoHost:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  postgres-operator.crunchydata.com/data: pgbackrest
              topologyKey: kubernetes.io/hostname

#      tolerations:
#      - effect: NoSchedule
#        key: role
#        operator: Equal
#        value: connection-poolers
#      priorityClassName: high-priority
#
#      topologySpreadConstraints:
#      - maxSkew: 1
#        topologyKey: my-node-label
#        whenUnsatisfiable: ScheduleAnyway
#        labelSelector:
#          matchLabels:
#            postgres-operator.crunchydata.com/pgbackrest: ""
#
#      securityContext:
#        fsGroup: 1001
#        runAsUser: 1001
#        runAsNonRoot: true
#        fsGroupChangePolicy: "OnRootMismatch"
#        runAsGroup: 1001
#        seLinuxOptions:
#          type: spc_t
#          level: s0:c123,c456
#        seccompProfile:
#          type: Localhost
#          localhostProfile: localhost/profile.json
#        supplementalGroups:
#        - 1001
#        sysctls:
#        - name: net.ipv4.tcp_keepalive_time
#          value: "600"
#        - name: net.ipv4.tcp_keepalive_intvl
#          value: "60"

    manual:
      repoName: repo1
      options:
      - --type=full
    repos:
    - name: repo1
      schedules:
        full: "0 0 * * 6" # run full backup weekly at 00:00
        differential: "0 1 * * 6" # run differential daily at 01:00
        incremental: "0 */2 * * *" # run incremental backup every 2 hours
      volume:
        volumeClaimSpec:
#          storageClassName: ""
          accessModes:
          - ReadWriteOnce
          resources:
            requests:
              storage: 1Gi
    - name: repo2
      s3:
        bucket: "<YOUR_AWS_S3_BUCKET_NAME>"
        endpoint: "<YOUR_AWS_S3_ENDPOINT>"
        region: "<YOUR_AWS_S3_REGION>"
#    - name: repo3
#      gcs:
#        bucket: "<YOUR_GCS_BUCKET_NAME>"
#    - name: repo4
#      azure:
#        container: "<YOUR_AZURE_CONTAINER>"
#
#    restore:
#      repoName: repo1
#      tolerations:
#      - effect: NoSchedule
#        key: role
#        operator: Equal
#        value: connection-poolers

pmm:
  enabled: false
  image:
    repository: percona/pmm-client
    tag: 2.43.1
#  imagePullPolicy: IfNotPresent
  secret: postgres-pmm-secret
  serverHost: monitoring-service
  querySource: pgstatmonitor
#  resources:
#    requests:
#      memory: 200M
#      cpu: 500m

patroni:
  # Some values of the Liveness/Readiness probes of the patroni container are calulated using syncPeriodSeconds by the following formulas:
  # - timeoutSeconds:   syncPeriodSeconds / 2;
  # - periodSeconds:    syncPeriodSeconds;
  # - failureThreshold: leaderLeaseDurationSeconds / syncPeriodSeconds.
  syncPeriodSeconds: 10
  leaderLeaseDurationSeconds: 30
  dynamicConfiguration:
    postgresql:
      parameters:
        max_parallel_workers: 2
        max_worker_processes: 2
        shared_buffers: 1GB
        work_mem: 2MB
        maintenance_work_mem: 1GB
        effective_cache_size: 3GB
        max_connections: 100
        max_locks_per_transaction: 128
        max_prepared_transactions: 100
        max_wal_size: 1GB
        min_wal_size: 80MB
        wal_buffers: 16MB
        checkpoint_timeout: 15min
        checkpoint_completion_target: 0.9
        checkpoint_flush_after: 256kB
        wal_writer_delay: 200ms
        wal_writer_flush_after: 1MB
        synchronous_commit: local
        synchronous_standby_names: "*"
        hot_standby: "on"
        max_standby_archive_delay: 30s
        max_standby_streaming_delay: 30s
        max_replication_slots: 10
        max_wal_senders: 10
        max_prepared_xacts: 100
        max_parallel_maintenance_workers: 2
        max_parallel_workers_per_gather: 2
        max_parallel_aggregate: 2
        max_parallel_degree: 2
        timezone: Africa/Kigali
      pg_hba:
      - host    all all 0.0.0.0/0 trust
      - host    all all ::/0 trust
      - hostssl all all 0.0.0.0/0 md5


  switchover:
    enabled: "true"
    targetInstance: ""

# extensions:
#   image: percona/percona-postgresql-operator:2.5.0
#   imagePullPolicy: Always
#   storage:
#     type: s3
#     bucket: pg-extensions
#     region: eu-central-1
#     endpoint: s3.eu-central-1.amazonaws.com
#     secret:
#       name: cluster1-extensions-secret
#   builtin:
#     pg_stat_monitor: true
#     pg_audit: true
#   custom:
#   - name: pg_cron
#     version: 1.6.1

secrets:
  name:
  # replication user password
  primaryuser:
  # superuser password
  postgres:
  # pgbouncer user password
  pgbouncer:
  # pguser user password
  pguser:
